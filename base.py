import aiohttp
from bs4 import BeautifulSoup


async def get_page(serch: str) -> str:
    url = f'https://ru.wikipedia.org/wiki/{serch}'
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(url) as response:
                if response.status != 200:
                    return '‚ùå –°—Ç–∞—Ç—å—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ü—Ä–æ–≤–µ—Ä—å –Ω–∞–ø–∏—Å–∞–Ω–∏–µ.'

                html = await response.text()
                soup = BeautifulSoup(html, 'lxml')
                div = soup.find('div', id='mw-content-text')
                first_p = div.find('p') if div else None

                if first_p and first_p.text.strip():
                    text = first_p.text.strip()
                    return text
                else:
                    return "üßê –°—Ç–∞—Ç—å—è –ø—É—Å—Ç–∞—è –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞."
    except Exception as e:
        return f'‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}'




    #     import requests
    #     responce = requests.get(url)
    #     if responce.status_code != 200:
    #         return '‚ùå –°—Ç–∞—Ç—å—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ü—Ä–æ–≤–µ—Ä—å –Ω–∞–ø–∏—Å–∞–Ω–∏–µ.'
    #
    #     soup = BeautifulSoup(responce.content, 'lxml')
    #     div = soup.find('div', id='mw-content-text')
    #     first_p = div.find('p')
    #
    #     if first_p and first_p.text.strip():
    #         text = first_p.text.strip()
    #         return text
    #     else:
    #         return "üßê –°—Ç–∞—Ç—å—è –ø—É—Å—Ç–∞—è –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞."
    # except Exception as e:
    #     return f'‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}'
